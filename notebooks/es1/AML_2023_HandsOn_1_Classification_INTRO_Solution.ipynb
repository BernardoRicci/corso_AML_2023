{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOCX+pVabB2xoJKOX8/dhs+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stefanogiagu/corso_AML_2023/blob/main/notebooks/es1/AML_2023_HandsOn_1_Classification_INTRO_Solution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# First HandsOn !\n",
        "In this HandsOn we will recap the basics of pyTorch with a simple classification task\n",
        "\n",
        "Slide for the day with the Task Description ([SLIDE](https://docs.google.com/presentation/d/1DCZn-I8bXQ_awkmR6I6u9be4MCHB0ljWTxBL9koOsXo/edit?usp=sharing))\n",
        "\n",
        "Jamboard for the day ([BOARD](https://jamboard.google.com/d/1n694UZc-sQK2AZnI4RX88d-hoPytOPo_-5wnt3Bwlbc/edit?usp=sharing))\n",
        "\n",
        "At the end of the lesson, I will put them as a pdf on the github"
      ],
      "metadata": {
        "id": "Vc27WTxo1IH0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Connect your drive!"
      ],
      "metadata": {
        "id": "D3MrmZxh1z9M"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "G3_Mxb_zqvTp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5975d71a-2c99-40d2-a227-59fd4e03f3e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive/', force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Go to the RiNNgs folder!\n",
        "use the command \"cd\" to  change directory\n",
        "\n",
        "\n",
        "```\n",
        "cd \"directory\"\n",
        "```\n",
        "\n",
        "\n",
        "then use \"ls\" (list) to show the files in the folder\n",
        "\n",
        "## Are you in the correct directory?\n"
      ],
      "metadata": {
        "id": "1KHTVfZW174G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/gdrive/MyDrive/RiNNgs"
      ],
      "metadata": {
        "id": "oBIaQZ0fsIEe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2230504-04e3-45db-cbfa-5a9f0c346818"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/RiNNgs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# What's in the directory you are in?\n",
        "\n"
      ],
      "metadata": {
        "id": "upQmA7_62NnN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "id": "EazN_73MsYQ4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb1ac2a9-e63c-435c-e636-40aec5baf76d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AML_2023_HandsOn_1_Classification_INTRO_FILLIN.ipynb    \u001b[0m\u001b[01;34mdata\u001b[0m/         \u001b[01;34mresults\u001b[0m/\n",
            "AML_2023_HandsOn_1_Classification_INTRO_Solution.ipynb  \u001b[01;34m__pycache__\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we need to get some files from github\n",
        "import os\n",
        "success = os.path.exists(\"./data_preprocess.py\")\n",
        "if not success:\n",
        " \n",
        "  ! wget https://raw.githubusercontent.com/stefanogiagu/corso_AML_2023/main/notebooks/es1/data_preprocess.py\n",
        " "
      ],
      "metadata": {
        "id": "B0-1m5mIejsu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc1c9a74-9a58-4571-dd24-146bf16fc7e6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-09 09:03:25--  https://raw.githubusercontent.com/stefanogiagu/corso_AML_2023/main/notebooks/es1/data_preprocess.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14603 (14K) [text/plain]\n",
            "Saving to: ‘data_preprocess.py’\n",
            "\n",
            "data_preprocess.py  100%[===================>]  14.26K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2023-03-09 09:03:25 (4.18 MB/s) - ‘data_preprocess.py’ saved [14603/14603]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0SC53DivhiGA",
        "outputId": "efe90db6-d272-4fa1-9475-aa676a56ce4d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AML_2023_HandsOn_1_Classification_INTRO_FILLIN.ipynb    data_preprocess.py\n",
            "AML_2023_HandsOn_1_Classification_INTRO_Solution.ipynb  \u001b[0m\u001b[01;34m__pycache__\u001b[0m/\n",
            "\u001b[01;34mdata\u001b[0m/                                                   \u001b[01;34mresults\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lets create all the folders needed"
      ],
      "metadata": {
        "id": "3Z6ZhhX-2jBh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "def CreateDir(path):\n",
        "\t# Create a directory if it does not exist\n",
        "\tsuccess = os.path.exists(path)\n",
        "\tif not success:\n",
        "\t\tos.makedirs(path)\n",
        "CreateDir(\"results\")#\n",
        "CreateDir(\"results/display\")\n",
        "CreateDir(\"results/preprocess\")\n",
        "CreateDir(\"data\")"
      ],
      "metadata": {
        "id": "DJdxcqAC2hkl"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "success = os.path.exists(\"data/event_08011.file\")\n",
        "if not success:\n",
        "  ! wget  https://raw.githubusercontent.com/stefanogiagu/corso_AML_2023/main/notebooks/es1/data/event_08011.file -P data/\n",
        "  ! wget -P data/ https://raw.githubusercontent.com/stefanogiagu/corso_AML_2023/main/notebooks/es1/data/RICH_map_corr_2017.data\n",
        "  ! wget -P data/ https://raw.githubusercontent.com/stefanogiagu/corso_AML_2023/main/notebooks/es1/data/data_08011.json"
      ],
      "metadata": {
        "id": "58eY82emgMt6"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# We need to build the dataset.\n",
        "How can we call a python code from a notebook script?\n",
        "\n",
        "Use the command\n",
        "\n",
        "\n",
        "```\n",
        "! python script.py ARG1,ARG2,...,ARGN\n",
        "```\n",
        "\n",
        "to call the \"data_preprocess.py\" that will find the run 0811 and form 16x16 images from it.\n",
        "\n",
        "arguments are \"08011 Conv 16 np_reco 0\"\n",
        "\n",
        "**Ignore all the warnings and the tensorflow calls. This function is doing a lot more than what we need**"
      ],
      "metadata": {
        "id": "giJtVnUQAOBJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! python data_preprocess.py 08011 Conv 16 np_reco 0"
      ],
      "metadata": {
        "id": "MCSz5yNYsrcP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9c56d96-a280-4ddc-90a8-89fee0f516d1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-03-09 09:03:30.721203: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-03-09 09:03:33.456419: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2023-03-09 09:03:33.456535: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2023-03-09 09:03:33.456553: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "*************************\n",
            "*  Data Pre-Processing  *\n",
            "*************************\n",
            "Dataset = 08011\n",
            "Model   = Conv\n",
            "Size    = 16\n",
            "Label   = np_reco\n",
            "Shuffle = 0\n",
            "Getting data for label np_reco\n",
            "Loading data/data_08011.json\n",
            " 20000 items in list hitlist\n",
            " 20000 items in list np_track\n",
            " 20000 items in list np_reco\n",
            " 20000 items in list np_gpu\n",
            " 20000 items in list ne_eop\n",
            " 20000 items in list ne_track\n",
            " 20000 items in list ne_reco\n",
            " 20000 items in list ne_gpu\n",
            "Processing selected label (np_reco)\n",
            "Example data\n",
            "*************\n",
            "Event      0\n",
            "*************\n",
            "   hitlist: ['1499', '1308', '1384', '1026', '1956', '1990', '1685', '1710', '310', '305', '177', '136', '244', '37', '79', '776', '718', '667', '670', '711', '713', '716', '747', '753', '748', '754', '751', '568', '569', '574', '636', '571', '594', '599', '631', '1458']\n",
            "  np_track: 1\n",
            "   np_reco: 2\n",
            "    np_gpu: -1\n",
            "    ne_eop: 0\n",
            "  ne_track: 2\n",
            "   ne_reco: 1\n",
            "    ne_gpu: -1\n",
            "Array\n",
            "[1499. 1308. 1384. 1026. 1956. 1990. 1685. 1710.  310.  305.  177.  136.\n",
            "  244.   37.   79.  776.  718.  667.  670.  711.  713.  716.  747.  753.\n",
            "  748.  754.  751.  568.  569.  574.  636.  571.  594.  599.  631. 1458.\n",
            "    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
            "    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
            "    0.    0.    0.    0.]\n",
            "Feature preprocessed\n",
            "[1499. 1308. 1384. 1026. 1956. 1990. 1685. 1710.  310.  305.  177.  136.\n",
            "  244.   37.   79.  776.  718.  667.  670.  711.  713.  716.  747.  753.\n",
            "  748.  754.  751.  568.  569.  574.  636.  571.  594.  599.  631. 1458.\n",
            "    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
            "    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
            "    0.    0.    0.    0.]\n",
            "<class 'numpy.ndarray'>\n",
            "(20000, 64)\n",
            "<class 'numpy.ndarray'>\n",
            "(20000, 4)\n",
            "X_SHAPE\n",
            "(20000, 64)\n",
            "X_SHAPE[0]\n",
            "20000\n",
            "Y_SHAPE\n",
            "(20000, 4)\n",
            "Preprocessing data from dataset 08011 for model Convof size  16\n",
            "Image 16 x 16  = 256 pixels\n",
            "X  max 150.050  min -493.980  range 644.030 bin 40.252 \n",
            "Y  max 286.740  min -316.140  range 602.880 bin 37.680 \n",
            "FILE MAP: data/RICH_map_corr_2017.data\n",
            "[ 114.05  105.05  114.05 ... -484.98 -493.98  -79.98]\n",
            "[ 135.92  120.34  104.75 ...  -87.38 -102.97 -102.97]\n",
            "[   0    1    2 ... 2022 2023 2031]\n",
            "[0.94410198 0.93012748 0.94410198 ... 0.0139745  0.         0.6428272 ]\n",
            "[0.74983413 0.72399151 0.6981323  ... 0.37944533 0.35358612 0.35358612]\n",
            "[14 14 14 ... -1 -1 -1]\n",
            "[11 11 10 ... -1 -1 -1]\n",
            "Imager map ready at results/display/imagerMap_human.txt (human format)\n",
            "Imager map ready at results/display/imagerMap.txt (computer format)\n",
            "processing image      0\n",
            "Images shape:\n",
            "(16, 16)\n",
            "Number of images:\n",
            "20000\n",
            "File results/preprocess/prova16.pdf ready\n",
            "Imager statistics ready at results/display/imagerCounts.txt\n",
            "Validation: X=(20000, 16, 16), y=(20000, 4)\n",
            "Data saved in results/preprocess/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Where are our files?\n",
        "\n",
        "The script will write two files in the results/preprocess folder that we created before.\n",
        "\n",
        "Check if you can find the files and that  *x_all_** is the rigth size (around 40 MB)\n",
        "\n",
        "Use the command\n",
        "\n",
        "\n",
        "```\n",
        "ls -lh \"path\"\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "9f16XiFJB9bP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! ls -lh  results/preprocess/"
      ],
      "metadata": {
        "id": "zmVx_yz3vnsJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76fc3ff3-be7c-42e6-97c3-e9ef054746fa"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 40M\n",
            "-rw------- 1 root root  82K Mar  9 09:03 prova16.pdf\n",
            "-rw------- 1 root root  40M Mar  9 09:03 x_all_08011.npy\n",
            "-rw------- 1 root root 313K Mar  9 09:03 y_all_08011.npy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Read the data, check the data format, print an element.\n",
        "\n",
        "\n",
        "*   Load the data with np.load\n",
        "*   Print the data shape\n",
        "*   Check the variable type\n",
        "*   Use plt.matshow() to print an element\n",
        "\n"
      ],
      "metadata": {
        "id": "lhRi7IqxExEp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "dataset = \"08011\"\n",
        "x_all = np.load( 'results/preprocess/' + 'x_all_{}.npy'.format(dataset))\n",
        "y_all = np.load( 'results/preprocess/' + 'y_all_{}.npy'.format(dataset))\n"
      ],
      "metadata": {
        "id": "4U6zPqehCrSs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"data shape : \", x_all.shape)\n",
        "print(\"label shape : \", y_all.shape)\n",
        "print(\"type of x_all[0]: \", type(x_all[0,0,0]))"
      ],
      "metadata": {
        "id": "iMu6kRcoFm6C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "to_plot = 10\n",
        "f,ax = plt.subplots(1,1,figsize=(5,5))\n",
        "ax.matshow(x_all[to_plot,:,:])\n",
        "ax.set_title(\"An example of class {}\".format(np.argmax(y_all[to_plot])),fontsize=30)"
      ],
      "metadata": {
        "id": "iULWnY-eGL9k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plot an histogram of the average intensity per class\n",
        "# A  trick:\n",
        "When you do this kind of data visualization, you are creating a lot of variables. If you wrap your code in a function you will keep the workspace clean."
      ],
      "metadata": {
        "id": "DKFBFZuDIx6s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_histo(x_all, y_all):\n",
        "\n",
        "  classes = np.argmax(y_all,axis=1)\n",
        "\n",
        "  intensities = x_all.reshape(x_all.shape[0],-1).mean(axis=1)\n",
        "  print(\"this shoud be [N,1] : \",intensities.shape)\n",
        "\n",
        "\n",
        "  f,ax = plt.subplots(1,1,figsize=(8,8))\n",
        "  for c in [0,1,2,3]:\n",
        "    ax.hist(intensities[classes==c],20,alpha=0.3,label=\"class {}\".format(c),density=True)\n",
        "\n",
        "  ax.set_xlabel(\"intensity\")\n",
        "  ax.legend()\n",
        "\n",
        "plot_histo(x_all, y_all)"
      ],
      "metadata": {
        "id": "WpOI3ML1HG_A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# remove the empty images\n",
        "def remove_empty(x_all, y_all):\n",
        "  intensities = x_all.reshape(x_all.shape[0],-1).mean(axis=1)\n",
        "  y_all = y_all[intensities>0]\n",
        "  x_all = x_all[intensities>0]\n",
        "  return x_all, y_all\n",
        "\n",
        "x_all, y_all = remove_empty(x_all, y_all)\n",
        "plot_histo(x_all, y_all)"
      ],
      "metadata": {
        "id": "I4YYz5J3NFR3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def piechartclasses(y_all):\n",
        "  classes = np.argmax(y_all, axis=1)\n",
        "  c = np.unique(classes)\n",
        "  arr_c = [np.mean(classes==i) for i in c]\n",
        "\n",
        "\n",
        " \n",
        "  # Creating plot\n",
        "  fig = plt.figure(figsize =(10, 7))\n",
        "  plt.pie(arr_c, labels = [\"0 rings\", \"1 ring\", \"2 rings\", \"3+ rings\"])\n",
        " \n",
        "  # show plot\n",
        "  plt.title(\"Class distribution\",fontsize=20)\n",
        "  plt.show()\n",
        "piechartclasses(y_all) "
      ],
      "metadata": {
        "id": "k6FXheUUIwIn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load images and prepare batches"
      ],
      "metadata": {
        "id": "Kc2yguLUHlMY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "import torch.utils.data as data\n",
        "\n",
        "\n",
        "class HitImageGenerator(Dataset):\n",
        "  \n",
        "\n",
        "    def __init__(self, X,y):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.X[idx]\n",
        "        label = self.y[idx]\n",
        "        #image = (image-image.reshape(-1).mean())/image.reshape(-1).std()\n",
        "        image=image/image.sum()\n",
        "        tensor_image = torch.from_numpy(image).unsqueeze(0).float()  # Add a channel dimension\n",
        "        tensor_label = torch.from_numpy(label).float()\n",
        "        return tensor_image, tensor_label\n",
        "\n",
        "class BalancedDataLoader(data.DataLoader):\n",
        "    def __init__(self, dataset, batch_size=1, shuffle=True):\n",
        "        self.dataset = dataset\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "\n",
        "        # If sampler is not provided, create a new one\n",
        "    \n",
        "        # Count the number of samples in each class\n",
        "        class_counts = torch.bincount(torch.tensor(np.argmax(dataset.y,axis=1)))\n",
        "\n",
        "        # Compute the weight of each sample\n",
        "        weights = 1.0 / class_counts[np.argmax(dataset.y,axis=1)]\n",
        "\n",
        "        # Create a sampler that samples each class with equal probability\n",
        "        sampler = torch.utils.data.sampler.WeightedRandomSampler(weights, len(weights))\n",
        "\n",
        "        super().__init__(dataset, batch_size=batch_size, sampler=sampler)\n",
        "\n"
      ],
      "metadata": {
        "id": "wDxssXykpY9K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(x_all, y_all, test_size=0.2, random_state=42)\n",
        "\n",
        "# Split training data into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "# Now you have X_train, y_train, X_val, y_val, X_test, and y_test as your splits\n",
        "\n",
        "\n",
        "# Lets split the dataset\n",
        "\n",
        "train_dataset = HitImageGenerator(X_train,y_train)\n",
        "train_loader = BalancedDataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "val_dataset = HitImageGenerator(X_val,y_val)\n",
        "val_loader = BalancedDataLoader(val_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "test_dataset = HitImageGenerator(X_test,y_test)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)# no balanced generator for the test"
      ],
      "metadata": {
        "id": "s5VPoy4kHlZr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uFY4bpnQNQ15"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "EpfcM-tPMmwZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, 4)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(32, 16, 2)\n",
        "        self.fc1 = nn.Linear(16 * 2 * 2, 64)\n",
        "        self.fc2 = nn.Linear(64, 64)\n",
        "        self.dpo1 = nn.Dropout(p=0.3)\n",
        "        self.fc3 = nn.Linear(64, 4)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.dpo1(x)\n",
        "        x = self.fc3(x)# the crossentropy loss in pytorch to the softmax for you\n",
        "        return x\n",
        "\n",
        "\n",
        "model = Net()"
      ],
      "metadata": {
        "id": "rf91t_SQMlnK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)"
      ],
      "metadata": {
        "id": "VKw2q7uCMr2g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(y_pred, y_true):\n",
        "    \"\"\"\n",
        "    Calculates the accuracy of the predicted labels.\n",
        "\n",
        "    Args:\n",
        "        y_pred (torch.Tensor): predicted labels\n",
        "        y_true (torch.Tensor): true labels\n",
        "\n",
        "    Returns:\n",
        "        float: accuracy score\n",
        "    \"\"\"\n",
        "    # Get the predicted class by finding the index of the maximum value along axis 1\n",
        "    y_pred = torch.argmax(y_pred, axis=1)\n",
        "    y_true = torch.argmax(y_true, axis=1)\n",
        "\n",
        "    # Calculate the number of correctly classified examples\n",
        "    correct = (y_pred == y_true).sum().item()\n",
        "\n",
        "    # Calculate the total number of examples\n",
        "    total = len(y_true)\n",
        "\n",
        "    # Calculate the accuracy\n",
        "    acc = correct / total\n",
        "\n",
        "    return acc"
      ],
      "metadata": {
        "id": "NM-vc79EjaAT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the number of epochs and the patience for early stopping\n",
        "num_epochs = 100\n",
        "patience = 15\n",
        "\n",
        "# Initialize the variables for tracking the best validation accuracy and the number of epochs since the best accuracy\n",
        "best_val_acc = 0.0\n",
        "epochs_since_best_val_acc = 0\n",
        "\n",
        "train_curve=[]\n",
        "val_curve=[]\n",
        "\n",
        "# Train loop\n",
        "for epoch in range(num_epochs):\n",
        "    # Training\n",
        "    model.train()\n",
        "    tmp_loss = 0\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        # Forward pass\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        optimizer.zero_grad()# clear the gradients\n",
        "        loss.backward()# gradient of the loss\n",
        "        optimizer.step()# new weigths\n",
        "        tmp_loss += loss.detach().numpy()\n",
        "    train_curve.append(tmp_loss/len(train_loader))  \n",
        "    # Validation\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        val_acc = 0.0\n",
        "        val_total = 0\n",
        "        val_loss = 0\n",
        "        for data, target in val_loader:\n",
        "            output = model(data)\n",
        "            val_loss += criterion(output, target).item()\n",
        "            \n",
        "            \n",
        "            val_acc += accuracy(output, target)\n",
        "\n",
        "        val_acc /=  len(val_loader)\n",
        "        val_loss /= len(val_loader)\n",
        "        val_curve.append(val_loss)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}, Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_acc:.4f}\")\n",
        "\n",
        "        # Check if the validation accuracy has improved\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            epochs_since_best_val_acc = 0\n",
        "            best_weights = model.state_dict()\n",
        "            torch.save(best_weights, 'results/best_weights.pth')\n",
        "            print(\"Best!\")\n",
        "        else:\n",
        "            epochs_since_best_val_acc += 1\n",
        "\n",
        "        # Check if early stopping is necessary\n",
        "        if epochs_since_best_val_acc >= patience:\n",
        "            print(\"Early stopping!\")\n",
        "            break\n",
        "plt.figure()\n",
        "plt.plot(train_curve,label=\"train\")\n",
        "plt.plot(val_curve,label=\"validation\")\n",
        "plt.legend()\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.yscale(\"log\")\n"
      ],
      "metadata": {
        "id": "CDdYeYaPeYWW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=Net()\n",
        "model.load_state_dict(torch.load('results/best_weights.pth'))\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "f2gJYemOlIYO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay\n",
        "\n",
        "def test_model(model, test_loader):\n",
        "    model.eval()\n",
        "\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in test_loader:\n",
        "            \n",
        "            outputs = model(inputs)\n",
        "            targets = targets.numpy()\n",
        "            outputs = outputs.numpy()\n",
        "\n",
        "            predicted = np.argmax(outputs, 1)\n",
        "            targets = np.argmax(targets , 1)\n",
        "\n",
        "            y_true.extend(targets)\n",
        "            y_pred.extend(predicted)\n",
        "\n",
        "    cm = confusion_matrix(y_true, y_pred,normalize=\"true\")\n",
        "\n",
        "    return np.array(y_true), np.array(y_pred), cm"
      ],
      "metadata": {
        "id": "3o2hWEa2of-e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_,_,cm=test_model(model, test_loader)"
      ],
      "metadata": {
        "id": "DvTuz_ujsT4n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
        "                              display_labels=[\"0 rings\", \"1 ring\", \"2 rings\", \"3+ rings\"])\n",
        "disp.plot()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wwmKpzbesqRd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aXgl6Q0KuUtY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}